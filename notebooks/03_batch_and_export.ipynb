{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7972f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from pathlib import Path\n",
    "#  import from src/ module\n",
    "sys.path.append(str(Path(\"..\").resolve() / \"src\"))\n",
    "\n",
    "from clean_prep import load_and_clean\n",
    "\n",
    "# output folder\n",
    "OUT_DIR = Path(\"..\").resolve() / \"data\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fed93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 16468027\n",
      "Timestamp min/max: 0 2671199\n"
     ]
    }
   ],
   "source": [
    "# 1) Load cleaned data\n",
    "df = load_and_clean(\"train\")\n",
    "\n",
    "print(\"Total rows:\", len(df))\n",
    "print(\"Timestamp min/max:\", df[\"timestamp\"].min(), df[\"timestamp\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7424f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rows: 200000\n",
      "Rest rows: 16268027\n"
     ]
    }
   ],
   "source": [
    "# 2) 200k sample (for quick testing and avoid large computes for limited snowflake credits)\n",
    "SAMPLE_N = 200_000\n",
    "df_sample = df.head(SAMPLE_N).copy()\n",
    "\n",
    "# Remaining rows for incremental batches\n",
    "df_rest = df.iloc[SAMPLE_N:].copy()\n",
    "\n",
    "print(\"Sample rows:\", len(df_sample))\n",
    "print(\"Rest rows:\", len(df_rest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "661c8d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cutoffs: 889986 1770562\n",
      "Batch sizes: 5422682 5422672 5422673\n",
      "Batch timestamp ranges:\n",
      "  b1: 42386 889986\n",
      "  b2: 889987 1770562\n",
      "  b3: 1770563 2671199\n"
     ]
    }
   ],
   "source": [
    "# Compute 3 batch cutoffs on the remaining data for incremental loads \n",
    "# Using quantiles on timestamp so batches are chronological\n",
    "q1, q2 = df_rest[\"timestamp\"].quantile([1/3, 2/3]).astype(int).tolist()\n",
    "\n",
    "batch_1 = df_rest[df_rest[\"timestamp\"] <= q1]\n",
    "batch_2 = df_rest[(df_rest[\"timestamp\"] > q1) & (df_rest[\"timestamp\"] <= q2)]\n",
    "batch_3 = df_rest[df_rest[\"timestamp\"] > q2]\n",
    "\n",
    "print(\"\\nCutoffs:\", q1, q2)\n",
    "print(\"Batch sizes:\", len(batch_1), len(batch_2), len(batch_3))\n",
    "print(\"Batch timestamp ranges:\")\n",
    "print(\"  b1:\", batch_1[\"timestamp\"].min(), batch_1[\"timestamp\"].max())\n",
    "print(\"  b2:\", batch_2[\"timestamp\"].min(), batch_2[\"timestamp\"].max())\n",
    "print(\"  b3:\", batch_3[\"timestamp\"].min(), batch_3[\"timestamp\"].max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ccd99e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Export complete:\n",
      " - C:\\Users\\User\\Documents\\Projects\\marketing_analytics_engineering_pipeline\\data\\criteo_sample_200k.parquet\n",
      " - C:\\Users\\User\\Documents\\Projects\\marketing_analytics_engineering_pipeline\\data\\criteo_batch_1.parquet\n",
      " - C:\\Users\\User\\Documents\\Projects\\marketing_analytics_engineering_pipeline\\data\\criteo_batch_2.parquet\n",
      " - C:\\Users\\User\\Documents\\Projects\\marketing_analytics_engineering_pipeline\\data\\criteo_batch_3.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4) Export to Parquet (fastest for Snowflake COPY)\n",
    "df_sample.to_parquet(OUT_DIR / \"criteo_sample_200k.parquet\", index=False)\n",
    "batch_1.to_parquet(OUT_DIR / \"criteo_batch_1.parquet\", index=False)\n",
    "batch_2.to_parquet(OUT_DIR / \"criteo_batch_2.parquet\", index=False)\n",
    "batch_3.to_parquet(OUT_DIR / \"criteo_batch_3.parquet\", index=False)\n",
    "\n",
    "print(\"\\n✅ Export complete:\")\n",
    "for p in [\n",
    "    OUT_DIR / \"criteo_sample_200k.parquet\",\n",
    "    OUT_DIR / \"criteo_batch_1.parquet\",\n",
    "    OUT_DIR / \"criteo_batch_2.parquet\",\n",
    "    OUT_DIR / \"criteo_batch_3.parquet\",\n",
    "]:\n",
    "    print(\" -\", p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
